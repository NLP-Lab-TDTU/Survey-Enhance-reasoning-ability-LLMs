# References

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](papers/wei2023chainofthought/2201.11903.pdf)
- [sDPO: Don't Use Your Data All at Once](papers/kim2024sdpo/2403.19270.pdf)
- [Advancing LLM Reasoning Generalists with Preference Trees](papers/yuan2024advancing/2404.02078.pdf)
- [ReFT: Representation Finetuning for Language Models](papers/wu2024reft/2404.03592.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](papers/devlin2019bert/1810.04805.pdf)
- [InternLM2 Technical Report](papers/cai2024internlm2/2403.17297.pdf)
