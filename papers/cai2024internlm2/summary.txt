 * The paper introduces InternLM2, an open-source Large Language Model (LLM) that outperforms previous models in comprehensive evaluations across 6 dimensions and 30 benchmarks.
* InternLM2 is trained using innovative pre-training and optimization techniques, with a meticulous pre-training process that includes the preparation of diverse data types such as text, code, and long-context data.
* The model efficiently captures long-term dependencies, initially trained on 4k tokens before advancing to 32k tokens in pre-training and fine-tuning stages, exhibiting remarkable performance on the 200k "Needle-in-a-Haystack" test.
* InternLM2 is further aligned using Supervised Fine-Tuning (SFT) and a novel Conditional Online Reinforcement Learning from Human Feedback (COOL RLHF) strategy that addresses conflicting human preferences and reward hacking.
* The authors release InternLM2 models in different training stages and model sizes, providing the community with insights into the modelâ€™s evolution.