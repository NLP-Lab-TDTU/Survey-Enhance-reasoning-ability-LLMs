 * The paper introduces OpenMathInstruct-1, a new math instruction tuning dataset with 1.8 million problem-solution pairs.
* The dataset is constructed by synthesizing code-interpreter solutions for GSM8K and MATH benchmarks using the Mixtral model.
* The authors compare the mathematical skills of the best closed-source LLMs, such as GPT-4, and the best open-source LLMs and find a wide gap.
* They propose a prompting novelty and scaling to construct the OpenMathInstruct-1 dataset, which is released under a commercially permissive license.
* The best model, OpenMath-CodeLlama-70B, trained on a subset of OpenMathInstruct-1, achieves a score of 84.6% on GSM8K and 50.7% on MATH, which is competitive with the best gpt-distilled models.
* The paper highlights the limitations of using proprietary models like GPT-4 for mathematical reasoning model development, such as legal restraints, cost, and lack of reproducibility.