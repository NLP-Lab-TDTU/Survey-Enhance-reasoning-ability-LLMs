 * The Yi model family is a series of language and multimodal models with strong multi-dimensional capabilities.
* The models are based on 6B and 34B pretrained language models, and are extended to chat models, 200K long context models, depth-upscaled models, and vision-language models.
* The base models perform well on a range of benchmarks, and the finetuned chat models have a high human preference rate on evaluation platforms.
* The performance of the Yi models is attributed to data quality resulting from data-engineering efforts, including a cascaded data deduplication and quality filtering pipeline for pretraining and manual verification of a small-scale instruction dataset for finetuning.
* The vision-language models combine a chat language model with a vision transformer encoder and are trained to align visual representations to the semantic space of the language model.
* The context length is extended to 200K through lightweight continual pretraining, and the performance is further improved by extending the depth of the pretrained checkpoint through continual pretraining.