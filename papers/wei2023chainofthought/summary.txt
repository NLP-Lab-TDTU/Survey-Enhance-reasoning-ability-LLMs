 * The paper proposes a method called "chain-of-thought" prompting to improve the complex reasoning abilities of large language models.
* This method involves providing a few chain of thought demonstrations as exemplars in prompting, which leads to the emergence of reasoning abilities in the models.
* The authors conduct experiments on three large language models and show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks.
* The empirical gains from this method can be significant, as demonstrated by a PaLM 540B model achieving state-of-the-art accuracy on the GSM8K benchmark of math word problems.
* The paper also provides examples of the chain-of-thought reasoning process, highlighting how the models break down complex problems into intermediate reasoning steps.
* The authors suggest that this method could be useful for a wide range of applications, including decision-making, tutoring, and explanation generation.